---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: postgres-rules
  namespace: monitoring
spec:
  groups:
    - name: postgres.rules
      rules:
        - alert: PostgresqlDown
          expr: pg_up == 0
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Postgresql down (instance {{ $labels.instance }})
            description: "Postgresql instance is down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlExporterError
          expr: pg_exporter_last_scrape_error > 0
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Postgresql exporter error (instance {{ $labels.instance }})
            description: "Postgresql exporter is showing errors. A query may be buggy in query.yaml\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlTooManyConnections
          expr: sum by (datname) (pg_stat_activity_count{datname!~"template.*|postgres"}) > pg_settings_max_connections * 0.8
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Postgresql too many connections (instance {{ $labels.instance }})
            description: "PostgreSQL instance has too many connections (> 80%).\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlDeadLocks
          expr: increase(pg_stat_database_deadlocks{datname!~"template.*|postgres"}[1m]) > 5
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: Postgresql dead locks (instance {{ $labels.instance }})
            description: "PostgreSQL has dead-locks\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlHighRollbackRate
          expr: sum by (namespace,datname) ((rate(pg_stat_database_xact_rollback{datname!~"template.*|postgres",datid!="0"}[3m])) / ((rate(pg_stat_database_xact_rollback{datname!~"template.*|postgres",datid!="0"}[3m])) + (rate(pg_stat_database_xact_commit{datname!~"template.*|postgres",datid!="0"}[3m])))) > 0.02
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: Postgresql high rollback rate (instance {{ $labels.instance }})
            description: "Ratio of transactions being aborted compared to committed is > 2 %\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlLowXidConsumption
          expr: rate(pg_txid_current[1m]) < 5
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Postgresql low XID consumption (instance {{ $labels.instance }})
            description: "Postgresql seems to be consuming transaction IDs very slowly\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlHighRateStatementTimeout
          expr: rate(postgresql_errors_total{type="statement_timeout"}[1m]) > 3
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Postgresql high rate statement timeout (instance {{ $labels.instance }})
            description: "Postgres transactions showing high rate of statement timeouts\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlHighRateDeadlock
          expr: increase(postgresql_errors_total{type="deadlock_detected"}[1m]) > 1
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Postgresql high rate deadlock (instance {{ $labels.instance }})
            description: "Postgres detected deadlocks\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlUnusedReplicationSlot
          expr: pg_replication_slots_active == 0
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: Postgresql unused replication slot (instance {{ $labels.instance }})
            description: "Unused Replication Slots\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlTooManyDeadTuples
          expr: ((pg_stat_user_tables_n_dead_tup > 10000) / (pg_stat_user_tables_n_live_tup + pg_stat_user_tables_n_dead_tup)) >= 0.1
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Postgresql too many dead tuples (instance {{ $labels.instance }})
            description: "PostgreSQL dead tuples is too large\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlSslCompressionActive
          expr: sum(pg_stat_ssl_compression) > 0
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Postgresql SSL compression active (instance {{ $labels.instance }})
            description: "Database connections with SSL compression enabled. This may add significant jitter in replication delay. Replicas should turn off SSL compression via `sslcompression=0` in `recovery.conf`.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: PostgresqlTooManyLocksAcquired
          expr: ((sum (pg_locks_count)) / (pg_settings_max_locks_per_transaction * pg_settings_max_connections)) > 0.20
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: Postgresql too many locks acquired (instance {{ $labels.instance }})
            description: "Too many locks acquired on the database. If this alert happens frequently, we may need to increase the postgres setting max_locks_per_transaction.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        # See https://github.com/samber/awesome-prometheus-alerts/issues/289#issuecomment-1164842737
        - alert: PostgresqlBloatIndexHigh(>80%)
          expr: pg_bloat_btree_bloat_pct > 80 and on (idxname) (pg_bloat_btree_real_size > 100000000)
          for: 1h
          labels:
            severity: warning
          annotations:
            summary: Postgresql bloat index high (> 80%) (instance {{ $labels.instance }})
            description: "The index {{ $labels.idxname }} is bloated. You should execute `REINDEX INDEX CONCURRENTLY {{ $labels.idxname }};`\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        # See https://github.com/samber/awesome-prometheus-alerts/issues/289#issuecomment-1164842737
        - alert: PostgresqlBloatTableHigh(>80%)
          expr: pg_bloat_table_bloat_pct > 80 and on (relname) (pg_bloat_table_real_size > 200000000)
          for: 1h
          labels:
            severity: warning
          annotations:
            summary: Postgresql bloat table high (> 80%) (instance {{ $labels.instance }})
            description: "The table {{ $labels.relname }} is bloated. You should execute `VACUUM {{ $labels.relname }};`\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: patroni-rules
  namespace: monitoring
spec:
  groups:
    - name: patroni.rules
      rules:
        - alert: PostgresqlPatroniClusterLocked
          expr: sum(patroni_cluster_unlocked) by (cluster_name)!=0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Patroni Cluster Locked
            description: "The postgresl cluster patroni is locked.  Please check the logs for more information"

        - alert: PostgresqlPatroniPaused
          expr: sum(patroni_cluster_paused) by (cluster_name)!=0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Patroni Cluster Paused
            description: "The postgresl cluster patroni is paused.  Please check the logs for more information"

        - alert: PostgresqlPatroniMasterIncorrect
          expr: sum(patroni_master) by (cluster_name)!=1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Patroni Master missing or too many
            description: "The number of patroni masters are either missing or more than 1"

        - alert: PostgresqlPatroniPendingRestart
          expr: sum(patroni_pending_restart) by (cluster_name)!=0
          for: 1h
          labels:
            severity: critical
          annotations:
            summary: Patroni is pending a restart
            description: "Patroni has been in pending restart state for > 1h"
